version: '3.8'

# ============================================================================
# LogsCrawler - Local Development / Single Host Deployment
#
# NO CONFIG FILE NEEDED - All configuration is via environment variables!
# For Swarm deployments, use devops/docker-compose.swarm.yml instead.
# ============================================================================

services:
  # OpenSearch for log storage and search
  opensearch:
    image: opensearchproject/opensearch:3.4.0
    container_name: logscrawler-opensearch
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - "DISABLE_SECURITY_PLUGIN=true"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - opensearch-data:/usr/share/opensearch/data
    ports:
      - "9200:9200"
      - "9600:9600"
    networks:
      - logscrawler-net
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200 >/dev/null || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 20


  # LogsCrawler Backend & Frontend
  logscrawler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: logscrawler-app
    # Run as root to access Docker socket (or use group_add with docker GID)
    user: root
    ports:
      - "5000:8000"
    volumes:
      # Mount Docker socket for Docker API access
      - /var/run/docker.sock:/var/run/docker.sock
      # Optional: Mount SSH keys for remote host access (SSH mode)
      # - ~/.ssh:/root/.ssh:ro
    environment:
      # ========== All configuration via environment variables ==========
      - LOGSCRAWLER_DEBUG=false

      # OpenSearch configuration
      - LOGSCRAWLER_OPENSEARCH__HOSTS=["http://opensearch:9200"]
      - LOGSCRAWLER_OPENSEARCH__INDEX_PREFIX=logscrawler

      # AI/Ollama configuration
      - LOGSCRAWLER_AI__MODEL=llama3.2:latest
      - LOGSCRAWLER_OLLAMA_URL=https://llm-dev.methodinfo.fr

      # Collector settings
      - LOGSCRAWLER_COLLECTOR__LOG_INTERVAL_SECONDS=30
      - LOGSCRAWLER_COLLECTOR__METRICS_INTERVAL_SECONDS=15
      - LOGSCRAWLER_COLLECTOR__LOG_LINES_PER_FETCH=500
      - LOGSCRAWLER_COLLECTOR__RETENTION_DAYS=7

      # Host configuration (JSON array)
      # Local Docker mode - monitors containers on this host via Docker socket
      - |
        LOGSCRAWLER_HOSTS=[
          {
            "name": "local-docker",
            "mode": "docker",
            "docker_url": "unix:///var/run/docker.sock"
          }
        ]

      # ========== Alternative configurations (uncomment as needed) ==========
      #
      # SSH mode - connect to remote hosts via SSH:
      # - |
      #   LOGSCRAWLER_HOSTS=[
      #     {"name": "local-docker", "mode": "docker"},
      #     {"name": "server-1", "mode": "ssh", "hostname": "192.168.1.10", "username": "deploy"},
      #     {"name": "server-2", "mode": "ssh", "hostname": "192.168.1.11", "username": "deploy"}
      #   ]
      #
      # Swarm mode with auto-discovery (discovers all Swarm nodes automatically):
      # - |
      #   LOGSCRAWLER_HOSTS=[
      #     {
      #       "name": "swarm-manager",
      #       "mode": "docker",
      #       "docker_url": "unix:///var/run/docker.sock",
      #       "swarm_manager": true,
      #       "swarm_routing": true,
      #       "swarm_autodiscover": true
      #     }
      #   ]

    extra_hosts:
      # Allows container to reach the host machine via "host.docker.internal"
      - "host.docker.internal:host-gateway"
    depends_on:
      opensearch:
        condition: service_healthy
    networks:
      - logscrawler-net
    restart: unless-stopped

networks:
  logscrawler-net:
    driver: bridge

volumes:
  opensearch-data:
    driver: local
  ollama-data:
    driver: local