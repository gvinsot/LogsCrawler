version: '3.9'

# ============================================================================
# LogsCrawler - Docker Swarm Deployment
# Deploy with: docker stack deploy -c docker-compose.swarm.yml logscrawler
#
# NO CONFIG FILE NEEDED - All configuration is via environment variables!
# The Swarm manager is configured with auto-discovery, so worker nodes
# are detected automatically.
# ============================================================================

services:
  # OpenSearch for log storage and search
  opensearch:
    image: opensearchproject/opensearch:3.4.0
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - "DISABLE_SECURITY_PLUGIN=true"
    volumes:
      - opensearch-data:/usr/share/opensearch/data
    networks:
      - internal
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200 >/dev/null || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.hostname == server-d
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # LogsCrawler Backend & Frontend
  logscrawler:
    image: registry.methodinfo.fr/logscrawler:latest
    build:
      context: ..
      dockerfile: Dockerfile
    # Run as root to access Docker socket
    user: root
    volumes:
      # Mount Docker socket for Swarm API access (required for auto-discovery)
      - /var/run/docker.sock:/var/run/docker.sock
      # Mount SSH keys for git clone/build operations on host
      - /root/.ssh:/gildas/.ssh:ro
    environment:
      # ========== All configuration via environment variables ==========
      - LOGSCRAWLER_DEBUG=false

      # OpenSearch configuration
      - LOGSCRAWLER_OPENSEARCH__HOSTS=["http://opensearch:9200"]
      - LOGSCRAWLER_OPENSEARCH__INDEX_PREFIX=logscrawler

      # AI/Ollama configuration
      - LOGSCRAWLER_AI__MODEL=llama3.2:latest
      - LOGSCRAWLER_OLLAMA_URL=https://llm-dev.methodinfo.fr

      # Collector settings
      - LOGSCRAWLER_COLLECTOR__LOG_INTERVAL_SECONDS=30
      - LOGSCRAWLER_COLLECTOR__METRICS_INTERVAL_SECONDS=15
      - LOGSCRAWLER_COLLECTOR__LOG_LINES_PER_FETCH=500
      - LOGSCRAWLER_COLLECTOR__RETENTION_DAYS=7
      
      # GitHub integration for Stacks tab
      - LOGSCRAWLER_GITHUB__TOKEN=${LOGSCRAWLER_GITHUB__TOKEN}
      - LOGSCRAWLER_GITHUB__USERNAME=gvinsot
      - LOGSCRAWLER_GITHUB__REPOS_PATH=~/repos
      - LOGSCRAWLER_GITHUB__SCRIPTS_PATH=~/PrivateNetwork
      # SSH config for running git/build commands on the Docker host (not in container)
      - LOGSCRAWLER_GITHUB__SSH_HOST=server-b
      - LOGSCRAWLER_GITHUB__SSH_USER=root
      
      # Host configuration (JSON array)
      # Using Swarm auto-discovery: only configure the manager, workers are discovered!
      - |
        LOGSCRAWLER_HOSTS=[
          {
            "name": "server-b",
            "mode": "docker",
            "docker_url": "unix:///var/run/docker.sock",
            "swarm_manager": true,
            "swarm_routing": true,
            "swarm_autodiscover": true
          }
        ]
    networks:
      - proxy
      - internal
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - opensearch
    deploy:
      replicas: 1
      labels:
        # Enable Traefik
        - "traefik.enable=true"

        # Define service port
        - "traefik.http.services.logscrawler.loadbalancer.server.port=8000"

        # HTTPS Router (main)
        - "traefik.http.routers.logscrawler.rule=Host(`logs.methodinfo.fr`)"
        - "traefik.http.routers.logscrawler.entrypoints=websecure"
        - "traefik.http.routers.logscrawler.tls.certresolver=letsencrypt"
        - "traefik.http.routers.logscrawler.middlewares=global@file,dashboard-auth@file"
        - "traefik.http.routers.logscrawler.service=logscrawler"

        # HTTP Router (redirect to HTTPS)
        - "traefik.http.routers.logscrawler-http.rule=Host(`logs.methodinfo.fr`)"
        - "traefik.http.routers.logscrawler-http.entrypoints=web"
        - "traefik.http.routers.logscrawler-http.middlewares=redirect-to-https@file"
        - "traefik.http.routers.logscrawler-http.service=noop@internal"
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.hostname == server-b

# ============================================================================
# Volumes
# ============================================================================
volumes:
  opensearch-data:
    driver: local

# ============================================================================
# Networks
# ============================================================================
networks:
  proxy:
    external: true
  internal:
    driver: overlay
    internal: true
    attachable: true
