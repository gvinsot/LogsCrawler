version: '3.9'

# ============================================================================
# LogsCrawler - Docker Swarm Deployment (Agent-Based Architecture)
# Deploy with: docker stack deploy -c docker-compose.swarm.yml logscrawler
#
# Architecture:
# - Backend: API server (read-only from OpenSearch, action queue)
# - Agent: Deployed on EVERY node (global mode), collects logs/metrics locally
# - OpenSearch: Storage for logs and metrics
#
# Security: Backend has NO access to Docker sockets. Agents run locally on
# each node and push data directly to OpenSearch.
# ============================================================================

services:
  # ==========================================================================
  # OpenSearch - Log and metrics storage
  # ==========================================================================
  opensearch:
    image: opensearchproject/opensearch:3.4.0
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - "DISABLE_SECURITY_PLUGIN=true"
    volumes:
      - opensearch-data:/usr/share/opensearch/data
    networks:
      - internal
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200 >/dev/null || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.hostname == server-d
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # ==========================================================================
  # LogsCrawler Backend - API Server
  # Docker socket mounted read-only for Swarm API queries (list containers/services)
  # Actual container operations (start/stop/exec) go through agents
  # ==========================================================================
  backend:
    image: registry.methodinfo.fr/logscrawler:latest
    build:
      context: ..
      dockerfile: Dockerfile
    # Run as root to access Docker socket for Swarm API queries
    user: root
    volumes:
      # Mount gildas's home directory for git operations and SSH keys
      - /home/gildas:/home/gildas
      # Docker socket for Swarm API queries (read-only)
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - LOGSCRAWLER_DEBUG=false
      # Use gildas's SSH keys for GitHub access
      - GIT_SSH_COMMAND=ssh -i /home/gildas/.ssh/id_rsa -o StrictHostKeyChecking=no

      # OpenSearch configuration (use stack-prefixed name)
      - LOGSCRAWLER_OPENSEARCH__HOSTS=["http://opensearch:9200"]
      - LOGSCRAWLER_OPENSEARCH__INDEX_PREFIX=logscrawler

      # AI/Ollama configuration
      - LOGSCRAWLER_AI__MODEL=llama3.2:latest
      - LOGSCRAWLER_OLLAMA_URL=https://llm-dev.methodinfo.fr

      # Collector settings (disabled - agents handle collection)
      # Set very high intervals to effectively disable backend collection
      - LOGSCRAWLER_COLLECTOR__LOG_INTERVAL_SECONDS=999999
      - LOGSCRAWLER_COLLECTOR__METRICS_INTERVAL_SECONDS=999999
      - LOGSCRAWLER_COLLECTOR__RETENTION_DAYS=7

      # GitHub integration for Stacks tab
      # No SSH_HOST configured = commands run locally in container
      # Repos are in /home/gildas/repos on the mounted home directory
      - LOGSCRAWLER_GITHUB__TOKEN=${LOGSCRAWLER_GITHUB__TOKEN}
      - LOGSCRAWLER_GITHUB__USERNAME=gvinsot
      - LOGSCRAWLER_GITHUB__REPOS_PATH=/home/gildas
      - LOGSCRAWLER_GITHUB__SCRIPTS_PATH=/home/gildas/PrivateNetwork

      # Swarm manager config - queries Swarm API to list all containers/services
      # Collection is disabled (agents handle it), this is only for listing
      - LOGSCRAWLER_HOSTS=[{"name":"swarm-manager","mode":"docker","docker_url":"unix:///var/run/docker.sock","swarm_manager":true,"swarm_autodiscover":true}]
    networks:
      - proxy
      - internal
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - opensearch
    deploy:
      replicas: 1
      labels:
        # Enable Traefik
        - "traefik.enable=true"

        # Define service port
        - "traefik.http.services.logscrawler.loadbalancer.server.port=8000"

        # HTTPS Router (main)
        - "traefik.http.routers.logscrawler.rule=Host(`logs.methodinfo.fr`)"
        - "traefik.http.routers.logscrawler.entrypoints=websecure"
        - "traefik.http.routers.logscrawler.tls.certresolver=letsencrypt"
        - "traefik.http.routers.logscrawler.middlewares=global@file,dashboard-auth@file"
        - "traefik.http.routers.logscrawler.service=logscrawler"

        # HTTP Router (redirect to HTTPS)
        - "traefik.http.routers.logscrawler-http.rule=Host(`logs.methodinfo.fr`)"
        - "traefik.http.routers.logscrawler-http.entrypoints=web"
        - "traefik.http.routers.logscrawler-http.middlewares=redirect-to-https@file"
        - "traefik.http.routers.logscrawler-http.service=noop@internal"
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.hostname == server-b

  # ==========================================================================
  # LogsCrawler Agent - Deployed on EVERY node (global mode)
  # Collects Docker logs/metrics locally and pushes to OpenSearch
  # ==========================================================================
  agent:
    image: registry.methodinfo.fr/logscrawler-agent:latest
    build:
      context: ..
      dockerfile: Dockerfile.agent
    # Run as root to access Docker socket
    user: root
    privileged: true
    pid: host
    volumes:
      # Mount Docker socket for LOCAL container access only
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # System and GPU device access for monitoring
      - /sys:/sys:ro
    environment:
      # AMD GPU visibility
      - AMD_VISIBLE_DEVICES=all
      # Agent ID: use node hostname (set by Swarm)
      - AGENT_AGENT_ID={{.Node.Hostname}}

      # Backend URL for polling actions (use stack-prefixed name)
      - AGENT_BACKEND_URL=http://backend:8000

      # OpenSearch configuration (use stack-prefixed name)
      - AGENT_OPENSEARCH__HOSTS=["http://opensearch:9200"]
      - AGENT_OPENSEARCH__INDEX_PREFIX=logscrawler

      # Docker socket path (inside container)
      - AGENT_DOCKER_URL=unix:///var/run/docker.sock

      # Collection intervals
      - AGENT_LOG_INTERVAL=30
      - AGENT_METRICS_INTERVAL=15
      - AGENT_ACTION_POLL_INTERVAL=2

      # Initial log lines to fetch
      - AGENT_LOG_LINES_PER_FETCH=500
    networks:
      - internal
    depends_on:
      - opensearch
      - backend
    deploy:
      # Deploy on ALL nodes in the Swarm
      mode: global
      restart_policy:
        condition: on-failure
        delay: 5s
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 64M

# ============================================================================
# Volumes
# ============================================================================
volumes:
  opensearch-data:
    driver: local

# ============================================================================
# Networks
# ============================================================================
networks:
  proxy:
    external: true
  internal:
    driver: overlay
    attachable: true
